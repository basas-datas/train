from transformers import AutoTokenizer, T5ForConditionalGeneration
from huggingface_hub import HfApi, HfFolder
import os

# üîê –¢–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
hf_token = os.environ["huggingface"]

# üìÅ –õ–æ–∫–∞–ª—å–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—å—é
local_model_dir = "./flan-t5-autobatch"

# üè∑Ô∏è –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–í–ê–ñ–ù–û: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ 'username/repo_name')
repo_id = "ajkndfjsdfasdf/flan-5-small-bigdataset"

# üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
api = HfApi()
HfFolder.save_token(hf_token)

# üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
try:
    api.repo_info(repo_id, token=hf_token)
    print(f"üì¶ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {repo_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
except:
    print(f"üì¶ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {repo_id} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º...")
    api.create_repo(repo_id=repo_id, token=hf_token, repo_type="model", exist_ok=True)

# üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
model = T5ForConditionalGeneration.from_pretrained(local_model_dir)
tokenizer = AutoTokenizer.from_pretrained(local_model_dir)

# üöÄ –ü—É—à–∏–º –≤ –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
model.push_to_hub(repo_id, token=hf_token, commit_message="üöÄ Push latest model to root")
tokenizer.push_to_hub(repo_id, token=hf_token, commit_message="üöÄ Push latest tokenizer to root")

print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤: https://huggingface.co/{repo_id}")
